Commands that you can run in the project root.

To compile the engine:
bazel build //:chaturaji_engine -c opt

Note: On Windows, always run the resulting executable from the root folder 
(e.g., .\bazel-bin\chaturaji_engine.exe) so it can find your Python scripts 
and DLLs correctly.

---------------------------------------------------------------------

To train a model:

Arguments:
  --train                 : Enter training mode.
  --iterations N          : Number of training iterations (default: 65536, check main.cpp).
  --games-per-iter N      : Number of self-play games per iteration (default: 128, check main.cpp).
  --target-sampling-rate VALUE : Target number of times each generated position is used for training (default: 1.5, check main.cpp).
  --train-batch N         : Batch size for the training steps (default: 1024, check main.cpp).
  --workers N             : Number of parallel self-play worker threads (default: 12, check main.cpp).
  --nn-batch N            : Max batch size for the central NN evaluator thread (default: 1024, check main.cpp).
  --worker-batch N        : Batch size for MCTS leaf evaluations *within* a worker thread before waiting for results (default: 48, check main.cpp).
  --sims N                : Number of MCTS simulations per move during self-play (default: 128, check main.cpp).
  --save-dir PATH         : Directory to save model checkpoints (default: "models").
  --load-model PATH       : Path to an existing .onnx model to continue training from (optional).
  --lr VALUE              : Learning rate (default: 0.02 for SGD, check train.cpp).
  --wd VALUE              : Weight decay (default: 0.0001 for SGD, check train.cpp).

IMPORTANT: This engine now uses SGD + Momentum (0.9). 
- Recommended LR for start: 0.1 or 0.02.
- Recommended WD: 0.0001 (Do NOT use 0.01 as with AdamW).
- To switch from AdamW to SGD, the latest .optimizer.pth file must be deleted manually before starting.

Example - Test Run (adjust workers/batches based on your CPU/GPU):
.\bazel-bin\chaturaji_engine.exe --train --iterations 1 --games-per-iter 5 --target-sampling-rate 1.5 --train-batch 64 --workers 4 --nn-batch 128 --worker-batch 16 --save-dir ./models --sims 64 --lr 0.02

Example - Serious Training Run (Resuming with SGD parameters):

CPU:
.\bazel-bin\chaturaji_engine.exe --train --iterations 32768 --games-per-iter 32 --target-sampling-rate 1.5 --train-batch 256 --workers 8 --nn-batch 64 --worker-batch 8 --save-dir ./models --sims 512 --max-buffer-size 100000 --lr 0.003 --wd 0.0001 --load-model "C:\Users\dell3\source\repos3\4pc-ffa-chaturaji-mcts-cpp\models\run_20251225_110842\iter_18.onnx"

iGPU:
.\bazel-bin\chaturaji_engine.exe --train --iterations 2000 --games-per-iter 50 --target-sampling-rate 2 --train-batch 512 --workers 24 --nn-batch 160 --worker-batch 8 --save-dir ./models --sims 256 --max-buffer-size 100000 --lr 0.03 --wd 0.0001 --temp-decay-move 80

Reduce learning rate as training progresses

---------------------------------------------------------------------

To simulate a game using a trained model (Inference Mode):

Arguments:
  --model PATH            : Path to the trained model (.onnx file). Default is "model.onnx".
  --sims N                : Number of MCTS simulations per move (default: 1000, check main.cpp).
  --mcts-batch N          : Batch size for *synchronous* MCTS NN calls during inference (default: 16, check main.cpp).

Example:
.\bazel-bin\chaturaji_engine.exe --model "model.onnx" --sims 256 --mcts-batch 16

Terminal Setup (Windows):
To ensure print_board displays the pieces correctly in the Windows terminal, run this command *before* running the engine executable:
chcp 65001

---------------------------------------------------------------------

To run a strength test between two models:

Arguments:
  --strength-test         : Enter strength test mode.
  --new-model PATH        : Path to the 'newer' model file (.onnx) (required).
  --old-model PATH        : Path to the 'older' model file (.onnx) (required).
  --games N               : Number of games to play (default: 100, check main.cpp).
  --sims N                : Number of MCTS simulations per move (default: 250, check main.cpp).
  --mcts-batch N          : Batch size for *synchronous* MCTS NN calls during the test (default: 64, check main.cpp).

Details:
  The test runs the specified number of games. In each game, the '--new-model'
  player assignment cycles through RED, BLUE, YELLOW, GREEN. The '--old-model'
  plays the other three colors. The final report shows the win rate for the
  '--new-model' based on achieving the highest score.

Example:
.\bazel-bin\chaturaji_engine.exe --strength-test --new-model "C:\Users\dell3\source\repos3\4pc-ffa-chaturaji-mcts-cpp\models\run_20251228_123212\iter_16.onnx" --old-model "C:\Users\dell3\source\repos3\4pc-ffa-chaturaji-mcts-cpp\models\run_20251228_123212\iter_1.onnx" --games 100 --sims 256 --mcts-batch 8

---------------------------------------------------------------------

To run Zobrist hashing tests:

Compile the test:
bazel build //:zobrist_test

Run the test and show output:
bazel test //:zobrist_test --test_output=all

---------------------------------------------------------------------

To run Perft (Performance Test):

Compile the perft:
bazel build //:perft

Run the test:
.\bazel-bin\perft.exe --depth 4 --divide